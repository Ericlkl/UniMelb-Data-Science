insulin-76,
bmi=27,
diabetes=0.25,
age=25))
# Predict (1,99,64,22,76,27,0.25,25)
hat2 = predict(bn2, newdata = list(pregnant=1,
glucose=99,
diastolic=64,
triceps=22,
insulin-76,
bmi=27,
diabetes=0.25,
age=25), type='response')
bn2
# Predict (1,99,64,22,76,27,0.25,25)
hat2 = predict(bn2, newdata = list(pregnant=1,
glucose=99,
diastolic=64,
triceps=22,
insulin-76,
bmi=27,
diabetes=0.25,
age=25), type='response')
pima
df
df$insulin
# Predict (1,99,64,22,76,27,0.25,25)
hat2 = predict(bn2, newdata = list(pregnant=1,
glucose=99,
diastolic=64,
triceps=22,
insulin-76,
bmi=27,
diabetes=0.25,
age=25), type='response')
# Predict (1,99,64,22,76,27,0.25,25)
hat2 = predict.glm(bn2, newdata = list(pregnant=1,
glucose=99,
diastolic=64,
triceps=22,
insulin-76,
bmi=27,
diabetes=0.25,
age=25), type='response')
# Predict (1,99,64,22,76,27,0.25,25)
hat2 = predict.glm(bn2Reduced, newdata = list(pregnant=1,
glucose=99,
diastolic=64,
triceps=22,
insulin-76,
bmi=27,
diabetes=0.25,
age=25), type='response')
bn2Reduced
# Predict (1,99,64,22,76,27,0.25,25)
hat2 = predict.glm(bn2Reduced, newdata = list(glucose=99,
bmi=27,
diabetes=0.25,
age=25), type='response')
# Predict (1,99,64,22,76,27,0.25,25)
hat2 = predict.glm(bn2Reduced, newdata = list(glucose=99,
bmi=27,
diabetes=0.25,
age=25), type='response')
CI2 = predict.glm(bnwReduced, newdata = list(glucose=99,
bmi=27,
diabetes=0.25,
age=25), type='link', se.fit=TRUE)
# 95% CI using N(0,1) and transformed using logit
ilogit(hat2*CI2$fit + c(-1,1)*1.96*CI2$se.fit)
# Predict (1,99,64,22,76,27,0.25,25)
hat2 = predict.glm(bn2Reduced, newdata = list(glucose=99,
bmi=27,
diabetes=0.25,
age=25), type='response')
CI2 = predict.glm(bnwReduced, newdata = list(glucose=99,
bmi=27,
diabetes=0.25,
age=25), type='link', se.fit=TRUE)
# 95% CI using N(0,1) and transformed using logit
ilogit(hat2*CI2$fit + c(-1,1)*1.96*CI2$se.fit)
CI2 = predict.glm(bnwReduced, newdata = list(glucose=99,
bmi=27,
diabetes=0.25,
age=25), type='link', se.fit=TRUE)
CI2 = predict.glm(bn2Reduced, newdata = list(glucose=99,
bmi=27,
diabetes=0.25,
age=25), type='link', se.fit=TRUE)
# 95% CI using N(0,1) and transformed using logit
ilogit(hat2*CI2$fit + c(-1,1)*1.96*CI2$se.fit)
# Load data
df = data("discoveries")
df
# Load data
df = data(discovers)
# Load data
df = data(discoveries)
df
str(df)
# Load data
data(discoveries)
df = discoveries
df
data.frame(discoveries)
df = data.frame(year=c(1860:1959), discoveries=discoveries)
df
# poisson model (log link function)
pm = glm(discoveries ~ year, data=discoveries, family=poisson)
# Load data
data(discoveries)
df = data.frame(year=c(1860:1959), discoveries=discoveries)
# poisson model (log link function)
pm = glm(discoveries ~ year, data=discoveries, family=poisson)
# poisson model (log link function)
pm = glm(discoveries ~ year, data=df, family=poisson)
summary(pm)
"""
t
"""
pm2 = glm(discoveries ~ year ~ year^2, data=df, family=poisson)
pm2 = glm(discoveries ~ year ~ I(year^2), data=df, family=poisson)
pm2 = glm(discoveries ~ year ~ l(year^2), data=df, family=poisson)
I
pm2 = glm(discoveries ~ year ~ I(year^2), data=df, family=poisson)
pm2 = glm(discoveries ~ year ~ matrix(year^2), data=df, family=poisson)
df$year_squared = (df$year)^2
df
pm2 = glm(discoveries ~ year ~ year_squared, data=df, family=poisson)
pm2 = glm(discoveries ~ year ~ year_squared, data=df, family=poisson)
pm2 = glm(discoveries ~ year + year_squared, data=df, family=poisson)
summary(pm2)
pairs(df)
plot(pm2)
pairs(df)
str(df)
pm
pm2
glm(disocveries ~ 0, data=df, family=poisson)
glm(discoveries ~ 0, data=df, family=poisson)
glm(discoveries ~ 1, data=df, family=poisson)
null
# Load data
data(discoveries)
df = data.frame(year=c(1860:1959), discoveries=discoveries)
# poisson model (log link function)
pm = glm(discoveries ~ year, data=df, family=poisson)
summary(pm) # Parameters are relevant
# Add the year squared variable
df$year_squared = (df$year)^2
pm2 = glm(discoveries ~ year + year_squared, data=df, family=poisson)
summary(pm2) # Parameters are much more relevant
# null model
null = glm(discoveries ~ 1, data=df, family=poisson)
# compare relevance values (deviance)
clear
cls
null$deviance
# Load data
data(discoveries)
df = data.frame(year=c(1860:1959), discoveries=discoveries)
# poisson model (log link function)
pm = glm(discoveries ~ year, data=df, family=poisson)
summary(pm) # Parameters are relevant
# Add the year squared variable
df$year_squared = (df$year)^2
pm2 = glm(discoveries ~ year + year_squared, data=df, family=poisson)
summary(pm2) # Parameters are much more relevant
# null model
null = glm(discoveries ~ 1, data=df, family=poisson)
# compare relevance values (deviance)
D1 = null$deviance - pm$deviance
D1
D2 = pm$deviance - pm2$deviance
D2
qf
qchi
qchisq()
qchisq
null
null$df.null
null$df.residual
qchisq(99)
qchisq(99, 99)
qchisq(99, 0.95)
qchisq(99, c(0, 0.95)
)
qchisq(99, D1)
pchisq
pchisq(D1, 1, lower.tail=FALSE)
pchisq(D2, 1, lower.tail=FALSE)
library(MASS)
data(ships)
str(ships)
library(MASS)
data(ships)
str(ships) # year and period should be timeseries or factors, not int
df1 = data.frame(ships)
df1$year = factor(df1$year)
df1$period = factor(df1$period)
str(df1)
plot(df1)
plot(df1$service)
plot(sort(df1$service))
plot(sort(log(df1$service)))
plot(sort(sqrt(df1$service)))
plot(sort(log(df1$service)))
plot(df1$year)
boxplot(df1$year)
plot(df1$year, df1$incidents)
df1$columns
df1.columns
colnames(df1)
for (i in colnames(df1)) {}
for (i in colnames(df1)) {}
plot(df1$i, df1$incidents)
for (i in colnames(df1)) {
plot(df1$i, df1$incidents)
}
for (i in colnames(df1)) {
plot(df1$i, df1$incidents)
}
for (i in colnames(df1)) {
plot(df1$i, df1$incidents)
}
for (i in colnames(df1)) {
plot(df1$i, df1$incidents)
}
pairs(df1)
plot(df1$service, df1$incidents)
pairs(df1)
df1$log_service = log(df1$service)
pm = glm(incidents ~ ., data=df, family=poisson)
pm = glm(incidents ~ ., data=df1, family=poisson)
df1
# Load data
data(discoveries)
df = data.frame(year=c(1860:1959), discoveries=discoveries)
# poisson model (log link function)
pm = glm(discoveries ~ year, data=df, family=poisson)
summary(pm) # Parameters are relevant
# Add the year squared variable
df$year_squared = (df$year)^2
pm2 = glm(discoveries ~ year + year_squared, data=df, family=poisson)
summary(pm2) # Parameters are much more relevant
# null model
null = glm(discoveries ~ 1, data=df, family=poisson)
# compare relevance values (deviance)
D1 = null$deviance - pm$deviance
pchisq(D1, 1, lower.tail=FALSE)
D2 = pm$deviance - pm2$deviance
pchisq(D2, 1, lower.tail=FALSE)
# We can conclude that adding the year variable from the null improves the model, and there is also significant
# improvement when adding the year_square variable. Hence, we can say that the discovery rate has changed over time.
library(MASS)
data(ships)
str(ships) # year and period should be timeseries or factors, not int
df1 = data.frame(ships)
df1$year = factor(df1$year)
df1$period = factor(df1$period)
pairs(df1) # service may need a transformation. Since there are values that are 0, a log transform wont work
df1$sqrt_service = sqrt(df1$service)
pm = glm(incidents ~ ., data=df1, family=poisson)
pm
df1
summary(pm)
step(pm)
new_pm = step(pm)
# period, year, type, service, sqrt_service seem to be irrelevant models from stepwise selection
summary(new_pm)
step(pm)
# period, year, type, service, sqrt_service seem to be irrelevant models from stepwise selection
summary(new_pm)
library(survival)
install.packages("survival")
library(survival)
data(infert)
str(infert)
df2 = data.frame(infert)
df2$pooled.stratum = factor(df2$pooled.stratum)
pairs(df2)
br = glm(case ~ ., data=df2, family=binomial)
summary(br)
colnames(df2)
colnames(df2)[-8]
colnames(df2)[-7]
c(colnames(df2)[-7])
glm(case ~ c(colnames(df2)[-7]), data=df2)
glm(case ~ c(colnames(df2)[-7]), data=df2, family=binomial)
glm(case ~ education + age + parity + induced + case + spontaneous, data=df2, family=binomial)
library(survival)
data(infert)
str(infert) # we dont use stratum since it confounded
df2 = data.frame(infert)
br = glm(case ~ education + age + parity + induced + case + spontaneous, data=df2, family=binomial)
summary(br)
br = glm(case ~ education + age + parity + induced + case + spontaneous, data=df2, family=binomial())
summary(br)
step(br)
summary(step(br))
br = glm(case ~ education + age + parity + induced + case + spontaneous, data=infert, family=binomial)
# Load data
data(discoveries)
df = data.frame(year=c(1860:1959), discoveries=discoveries)
# poisson model (log link function)
pm = glm(discoveries ~ year, data=df, family=poisson)
summary(pm) # Parameters are relevant
# Add the year squared variable
df$year_squared = (df$year)^2
pm2 = glm(discoveries ~ year + year_squared, data=df, family=poisson)
summary(pm2) # Parameters are much more relevant
# null model
null = glm(discoveries ~ 1, data=df, family=poisson)
# compare relevance values (deviance) with 1 parameter difference between models
D1 = null$deviance - pm$deviance
pchisq(D1, 1, lower.tail=FALSE)
D2 = pm$deviance - pm2$deviance
pchisq(D2, 1, lower.tail=FALSE)
D1
D2
?print
format(round(0.1, 50), nsmall = 50)
format(round(0.1, 50))
format(round(0.1, 50), nsmall=2)
format(round(0.1, 50), nsmall=40)
format(round(0.1, 50), nsmall=20)
# Setup FOR LOGIT
setwd('C:\\Users\\akira\\Documents\\GitHub\\final_sem\\Modern Applied Stats\\assignments\\A1')
library(faraway)
data(orings)
n = 6
# estimation beta
INITIAL_PARAMS = c(50, -0.05) # Begin at 50 with learning rate alpha = -0.05
logL = function(beta, data) {
n = 6
y = data$damage
eta = cbind(1, data$temp) %*% beta
p = probit(eta)
return(sum(y * log(p / (1 - p)) + n * log(1 - p)))
}
beta.hat = optim(INITIAL_PARAMS, logL, data=orings, control=list(fnscale=-1))$par
beta0 = beta.hat[1]
beta1 = beta.hat[2]
beta.hat = optim(INITIAL_PARAMS, logL, data=orings, control=list(fnscale=-1))$par
# Setup FOR LOGIT
setwd('C:\\Users\\akira\\Documents\\GitHub\\final_sem\\Modern Applied Stats\\assignments\\A1')
library(faraway)
data(orings)
n = 6
# funcs
probit = function(eta) pnorm(eta)
iprobit = function(p) qnorm(p)
probit.dash = function(x) dnorm(x)
# estimation beta
INITIAL_PARAMS = c(50, -0.05) # Begin at 50 with learning rate alpha = -0.05
logL = function(beta, data) {
n = 6
y = data$damage
eta = cbind(1, data$temp) %*% beta
p = probit(eta)
return(sum(y * log(p / (1 - p)) + n * log(1 - p)))
}
beta.hat = optim(INITIAL_PARAMS, logL, data=orings, control=list(fnscale=-1))$par
beta0 = beta.hat[1]
beta1 = beta.hat[2]
optim(INITIAL_PARAMS, logL, data=orings, control=list(fnscale=-1))
# funcs
probit = function(eta) pnorm(eta)
iprobit = function(p) qnorm(p)
probit.dash = function(x) dnorm(x)
# estimation beta
INITIAL_PARAMS = c(50, -0.05) # Begin at 50 with learning rate alpha = -0.05
logL = function(beta, data) {
n = 6
y = data$damage
eta = cbind(1, data$temp) %*% beta
p = probit(eta)
return(sum(y * log(p / (1 - p)) + n * log(1 - p)))
}
beta.hat = optim(INITIAL_PARAMS, logL, data=orings, control=list(fnscale=-1))$par
# estimation beta
INITIAL_PARAMS = c(10, -0.05) # Begin at 50 with learning rate alpha = -0.05
logL = function(beta, data) {
n = 6
y = data$damage
eta = cbind(1, data$temp) %*% beta
p = probit(eta)
return(sum(y * log(p / (1 - p)) + n * log(1 - p)))
}
beta.hat = optim(INITIAL_PARAMS, logL, data=orings, control=list(fnscale=-1))$par
beta.hat
R_CHECK = glm(cbind(damage,6-damage) ~ ., family=binomial(link='probit'), orings)
summary(R_CHECK)
beta0 = beta.hat[1]
beta1 = beta.hat[2]
# estimate p.hat LOGIT
p.hat = probit(beta.hat[1] + orings$temp * beta.hat[2])
p.hat
eta = beta0 + beta1 * orings$tem,p
eta = beta0 + beta1 * orings$temp
pnorm(eta)
dnorm(eta)
eta
eta = beta0
eta
probit.dash(eta)
eta
beta0
beta1
cbind(beta0, beta1)
rbind(beta0, beta1)
eta.matrix = x.vector %*% beta.vector
x.vector = c(1, orings$temp)
beta.vector = rbind(beta0, beta1)
eta.matrix = x.vector %*% beta.vector
y.vector = orings$damage
eta.vector
x.vector = c(1, orings$temp)
beta.vector = rbind(beta0, beta1)
eta.matrix = x.vector %*% beta.vector
y.vector = orings$damage
eta.matrix
x.vector = c(1, orings$temp)
beta.vector = rbind(beta0, beta1)
x.vector %*% beta.vector
t(x.vector) %*% beta.vector
beta.vector = c(beta0, beta1)
eta.matrix = x.vector %*% beta.vector
x.vector
beta.vector
X
length(orings$temp)
x.vector = cbind(1, orings$temp)
x.vector
X = cbind(1, orings$temp)
source('~/GitHub/final_sem/Modern Applied Stats/assignments/A1/R.R', echo=TRUE)
beta.vector = c(beta0, beta1)
X%*%beta
t(X)%*%beta
x
x
x
X
X %*% t(beta.vector)
beta.vector
t(beta.vector)
beta.vector = cbind(beta0, beta1)
beta.vector
t(beta.vector)
X %*% t(beta.vector)
eta = X %*% t(beta.vector)
eta
LEFT = y * (probit.dash(eta) + eta * probit(eta)) / probit(eta)^2
y = orings$damage
LEFT = y * (probit.dash(eta) + eta * probit(eta)) / probit(eta)^2
LEFT
6 -y
RIGHT = (6 - y) * (probit.dash(eta) - eta * (1 - probit(eta))) / (1 - probit(eta))^2
RIGHT
result = -sum(probit.dash(eta) * (LEFT + RIGHT))
result
result = probit.dash(eta) * (LEFT + RIGHT)
result
-sum(
result = -sum(probit.dash(eta) * (LEFT + RIGHT))
X = cbind(1, orings$temp[1])
X = cbind(1, orings$temp[1])
beta.vector = cbind(beta0, beta1)
eta = X %*% t(beta.vector)
y = orings$damage
LEFT = y * (probit.dash(eta) + eta * probit(eta)) / probit(eta)^2
RIGHT = (6 - y) * (probit.dash(eta) - eta * (1 - probit(eta))) / (1 - probit(eta))^2
result = -sum(probit.dash(eta) * (LEFT + RIGHT))
result
result * X%*%t(X)
result * t(X)%*%X
result = -sum(probit.dash(eta) * (LEFT + RIGHT)) * t(X)%*%X
X = cbind(1, orings$temp)
beta.vector = cbind(beta0, beta1)
eta = X %*% t(beta.vector)
y = orings$damage
LEFT = y * (probit.dash(eta) + eta * probit(eta)) / probit(eta)^2
RIGHT = (6 - y) * (probit.dash(eta) - eta * (1 - probit(eta))) / (1 - probit(eta))^2
result = -sum(probit.dash(eta) * (LEFT + RIGHT)) * t(X)%*%X
result
sqrt(result)
result = sum(probit.dash(eta) * (LEFT + RIGHT)) * t(X)%*%X
result
sqrt(result)
solve(result)
Iinv = solve(result) # Inverse fisher information matrix
beta0.error = sqrt(Iinv[1,1])
beta1.error = sqrt(Iinv[2,2])
# 95% CI for beta estimates
z.alpha = qnorm(0.975)
CI.beta0 = beta0 + c(-1, 1) * z.alpha * beta0.error
CI.beta1 = beta1 + c(-1, 1) * z.alpha * beta1.error
CI.beta0
CI.beta1
# EXPECTED RESPONSE WITH GLM
R_CHECK = glm(cbind(damage,6-damage) ~ ., family=binomial(link='probit'), orings)
summary(R_CHECK)
confint(R_CHECK, 'temp', level=0.95)
CI.beta1
result = sum(probit.dash(eta) * (LEFT + RIGHT) * t(X)%*%X)
orings$temp
sum(probit.dash(eta) * (LEFT + RIGHT))
result
-sum(probit.dash(eta) * (LEFT + RIGHT))
eta
beta.vector
X
